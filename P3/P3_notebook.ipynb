{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/python2env/lib/python2.7/site-packages/matplotlib/colors.py:680: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.\n",
      "  not cbook.is_string_like(colors[0]):\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from librosa.display import specshow\n",
    "from librosa.feature import mfcc\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d13078f03088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     x = np.append(\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m173\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run to get LSTM predictions\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from librosa.display import specshow\n",
    "from librosa.feature import mfcc\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Open file, save as reader object\n",
    "f = open('train.csv', 'r')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "n_mfcc = 20\n",
    "x = np.zeros((1, n_mfcc * 173))\n",
    "y = []\n",
    "for row in reader:\n",
    "    y.append(int(float(row[-1])))\n",
    "    x = np.append(\n",
    "        x, mfcc(np.array(map(float, row[:-1])), n_mfcc = n_mfcc).flatten().reshape((1, n_mfcc * 173)), axis = 1\n",
    "    )\n",
    "\n",
    "x = np.delete(x, 0, 0)\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(\"HERE\")\n",
    "# input_shape is (batch_size, timesteps, input_dim)\n",
    "data_dim = n_mfcc * 173\n",
    "timesteps = 1\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6325/6325 [==============================] - 5s 812us/step - loss: 1.3709 - acc: 0.5382\n",
      "Epoch 2/20\n",
      "6325/6325 [==============================] - 4s 690us/step - loss: 0.4270 - acc: 0.8653\n",
      "Epoch 3/20\n",
      "6325/6325 [==============================] - 4s 700us/step - loss: 0.2572 - acc: 0.9232\n",
      "Epoch 4/20\n",
      "6325/6325 [==============================] - 4s 709us/step - loss: 0.1960 - acc: 0.9391\n",
      "Epoch 5/20\n",
      "6325/6325 [==============================] - 5s 741us/step - loss: 0.1725 - acc: 0.9475\n",
      "Epoch 6/20\n",
      "6325/6325 [==============================] - 5s 718us/step - loss: 0.1421 - acc: 0.9551\n",
      "Epoch 7/20\n",
      "6325/6325 [==============================] - 4s 675us/step - loss: 0.1235 - acc: 0.9600\n",
      "Epoch 8/20\n",
      "6325/6325 [==============================] - 5s 722us/step - loss: 0.1072 - acc: 0.9660\n",
      "Epoch 9/20\n",
      "6325/6325 [==============================] - 4s 695us/step - loss: 0.0955 - acc: 0.9701\n",
      "Epoch 10/20\n",
      "6325/6325 [==============================] - 5s 737us/step - loss: 0.0885 - acc: 0.9730\n",
      "Epoch 11/20\n",
      "6325/6325 [==============================] - 4s 696us/step - loss: 0.0778 - acc: 0.9753\n",
      "Epoch 12/20\n",
      "6325/6325 [==============================] - 4s 695us/step - loss: 0.0782 - acc: 0.9750\n",
      "Epoch 13/20\n",
      "6325/6325 [==============================] - 4s 691us/step - loss: 0.0763 - acc: 0.9753\n",
      "Epoch 14/20\n",
      "6325/6325 [==============================] - 4s 671us/step - loss: 0.0632 - acc: 0.9804\n",
      "Epoch 15/20\n",
      "6325/6325 [==============================] - 4s 672us/step - loss: 0.0600 - acc: 0.9799\n",
      "Epoch 16/20\n",
      "6325/6325 [==============================] - 4s 657us/step - loss: 0.0583 - acc: 0.9810\n",
      "Epoch 17/20\n",
      "6325/6325 [==============================] - 4s 692us/step - loss: 0.0584 - acc: 0.9810\n",
      "Epoch 18/20\n",
      "6325/6325 [==============================] - 4s 701us/step - loss: 0.0511 - acc: 0.9829\n",
      "Epoch 19/20\n",
      "6325/6325 [==============================] - 4s 701us/step - loss: 0.0437 - acc: 0.9880\n",
      "Epoch 20/20\n",
      "6325/6325 [==============================] - 4s 703us/step - loss: 0.0258 - acc: 0.9921\n"
     ]
    }
   ],
   "source": [
    "n = 6325\n",
    "x = x.reshape((n, timesteps, data_dim))\n",
    "\n",
    "def lstm_f():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences = True, input_shape = (timesteps, data_dim)))\n",
    "    model.add(LSTM(100, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "    model.add(LSTM(100))  # return a single vector of dimension 32\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    model.compile(\n",
    "        loss = 'categorical_crossentropy', \n",
    "        optimizer = 'adam', \n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn = lstm_f, epochs = 20, verbose = 1)\n",
    "estimator.fit(x, y)\n",
    "\n",
    "def write_predictions(predictions, ids, outfile):\n",
    "    \"\"\"\n",
    "    assumes len(predictions) == len(ids), and that predictions[i] is the\n",
    "    index of the predicted class with the malware_classes list above for \n",
    "    the executable corresponding to ids[i].\n",
    "    outfile will be overwritten\n",
    "    \"\"\"\n",
    "    with open(outfile,\"w+\") as f:\n",
    "        # write header\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i, history_id in enumerate(ids):\n",
    "            f.write(\"%s,%d\\n\" % (history_id, predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 20000 into shape (1000,1,88200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aeb6bdae6e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m88200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mwrite_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm_preds.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 20000 into shape (1000,1,88200)"
     ]
    }
   ],
   "source": [
    "# Read in test data\n",
    "# del x\n",
    "# del y\n",
    "\n",
    "f = open('test.csv', 'r')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "n_mfcc = 20\n",
    "xtest = np.zeros((1, n_mfcc * 173))\n",
    "for row in reader:\n",
    "    xtest = np.append(\n",
    "        xtest, \n",
    "        mfcc(np.array(map(float, row[:-1])), n_mfcc = n_mfcc).flatten().reshape((1, n_mfcc * 173)), axis = 1\n",
    "    )\n",
    "    \n",
    "xtest = np.delete(xtest, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 297us/step\n"
     ]
    }
   ],
   "source": [
    "xtest = xtest.reshape(1000, 1, 20)\n",
    "preds = estimator.predict(xtest)\n",
    "write_predictions(preds, range(1000), 'lstm_preds_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 54s 67ms/step - loss: 1.8643 - acc: 0.8700\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 37s 47ms/step - loss: 0.9837 - acc: 0.9650\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 33s 41ms/step - loss: 0.4085 - acc: 0.9888\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 33s 42ms/step - loss: 0.1751 - acc: 0.9962\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 35s 44ms/step - loss: 0.0781 - acc: 0.9962\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 46s 57ms/step - loss: 0.0339 - acc: 0.9962\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.0176 - acc: 0.9962\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 29s 37ms/step - loss: 0.0137 - acc: 0.9962\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 29s 36ms/step - loss: 0.0121 - acc: 0.9962\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.0111 - acc: 0.9962\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 31s 39ms/step - loss: 0.0104 - acc: 0.9962\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.0098 - acc: 0.9962\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 32s 40ms/step - loss: 0.0094 - acc: 0.9962\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 29s 37ms/step - loss: 0.0090 - acc: 0.9962\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 33s 41ms/step - loss: 0.0086 - acc: 0.9962\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 38s 47ms/step - loss: 0.0083 - acc: 0.9962\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 33s 42ms/step - loss: 0.0079 - acc: 0.9962\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 35s 44ms/step - loss: 0.0076 - acc: 0.9962\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 36s 45ms/step - loss: 0.0073 - acc: 0.9962\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 30s 38ms/step - loss: 0.0068 - acc: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c22685710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_shape is (batch_size, timesteps, input_dim)\n",
    "data_dim = 88200\n",
    "timesteps = 1\n",
    "num_classes = 10\n",
    "\n",
    "x = x.reshape((n, timesteps, data_dim))\n",
    "\n",
    "# xtest1 = xtest.reshape((50, timesteps, data_dim))\n",
    "# xtrain1 = xtrain.reshape((50, timesteps, data_dim))\n",
    "# assert(xtrain1.shape == (50, timesteps, data_dim))\n",
    "# assert(ytrain.shape == (50, num_classes))\n",
    "\n",
    "def lstm_f():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences = True, input_shape = (timesteps, data_dim)))\n",
    "    model.add(LSTM(100, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "    model.add(LSTM(100))  # return a single vector of dimension 32\n",
    "    model.add(Dense(10, activation = 'softmax'))\n",
    "    model.compile(\n",
    "        loss = 'categorical_crossentropy', \n",
    "        optimizer = 'adam', \n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn = lstm_f, epochs = 20, verbose = 1)\n",
    "estimator.fit(x, y)\n",
    "# preds = estimator.predict(xtest1)\n",
    "# print('Score:', estimator.score(xtest1, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_7_input to have 3 dimensions, but got array with shape (1000, 88200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8d475be32b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/python2env/lib/python2.7/site-packages/keras/wrappers/scikit_learn.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2env/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1025\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/python2env/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected lstm_7_input to have 3 dimensions, but got array with shape (1000, 88200)"
     ]
    }
   ],
   "source": [
    "def write_predictions(predictions, ids, outfile):\n",
    "    \"\"\"\n",
    "    assumes len(predictions) == len(ids), and that predictions[i] is the\n",
    "    index of the predicted class with the malware_classes list above for \n",
    "    the executable corresponding to ids[i].\n",
    "    outfile will be overwritten\n",
    "    \"\"\"\n",
    "    with open(outfile,\"w+\") as f:\n",
    "        # write header\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i, history_id in enumerate(ids):\n",
    "            f.write(\"%s,%d\\n\" % (history_id, predictions[i]))\n",
    "\n",
    "# Read in test data\n",
    "del x\n",
    "del y\n",
    "\n",
    "f = open('test.csv', 'r')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "xtest = np.zeros((1, 88200))\n",
    "for row in reader:\n",
    "    xtest = np.append(\n",
    "        xtest, \n",
    "        np.array(map(float, row[1:])).reshape((1, 88200)), \n",
    "        axis = 0\n",
    "    )\n",
    "\n",
    "xtest = np.delete(xtest, 0, 0)\n",
    "\n",
    "xtest = xtest.reshape(1000, 1, 88200)\n",
    "preds = estimator.predict(xtest)\n",
    "write_predictions(preds, range(1000), 'lstm_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def basic_f():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim = 88200, activation = 'relu', kernel_initializer = 'normal'))\n",
    "    model.add(Dense(100, activation = 'relu'))\n",
    "    model.add(Dense(10, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn = basic_f, epochs = 50, verbose = 0)\n",
    "estimator.fit(xtrain, ytrain)\n",
    "preds = estimator.predict(xtest)\n",
    "print('Score:', estimator.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.metrics_names\n",
    "loss, accuracy = model.evaluate(x, y)\n",
    "predictions = model.predict(x) # floating points between 0 and 1\n",
    "class_preds = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 2s 29ms/step - loss: 4.4557\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 3.8314\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2.9581\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 2.1825\n",
      "Epoch 5/50\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 1.7495\n",
      "Epoch 6/50\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 1.3774\n",
      "Epoch 7/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 1.1281\n",
      "Epoch 8/50\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.9887\n",
      "Epoch 9/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.9068\n",
      "Epoch 10/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.8632\n",
      "Epoch 11/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.8079\n",
      "Epoch 12/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.7671\n",
      "Epoch 13/50\n",
      "70/70 [==============================] - 1s 10ms/step - loss: 0.7215\n",
      "Epoch 14/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.6903\n",
      "Epoch 15/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.6558\n",
      "Epoch 16/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.6227\n",
      "Epoch 17/50\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 0.5873\n",
      "Epoch 18/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.5693\n",
      "Epoch 19/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5637\n",
      "Epoch 20/50\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.5490\n",
      "Epoch 21/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5352\n",
      "Epoch 22/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.5263\n",
      "Epoch 23/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5191\n",
      "Epoch 24/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.5034\n",
      "Epoch 25/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4955\n",
      "Epoch 26/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4926\n",
      "Epoch 27/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4729\n",
      "Epoch 28/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4729\n",
      "Epoch 29/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4781\n",
      "Epoch 30/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4742\n",
      "Epoch 31/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4717\n",
      "Epoch 32/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4713\n",
      "Epoch 33/50\n",
      "70/70 [==============================] - 1s 15ms/step - loss: 0.4642\n",
      "Epoch 34/50\n",
      "70/70 [==============================] - 1s 18ms/step - loss: 0.4634\n",
      "Epoch 35/50\n",
      "70/70 [==============================] - 1s 20ms/step - loss: 0.4757\n",
      "Epoch 36/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4769\n",
      "Epoch 37/50\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.4674\n",
      "Epoch 38/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4567\n",
      "Epoch 39/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4553\n",
      "Epoch 40/50\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.4610\n",
      "Epoch 41/50\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.4632\n",
      "Epoch 42/50\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 0.4570\n",
      "Epoch 43/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4441\n",
      "Epoch 44/50\n",
      "70/70 [==============================] - 1s 16ms/step - loss: 0.4583\n",
      "Epoch 45/50\n",
      "70/70 [==============================] - 1s 14ms/step - loss: 0.4626\n",
      "Epoch 46/50\n",
      "70/70 [==============================] - 1s 13ms/step - loss: 0.4587\n",
      "Epoch 47/50\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.4588\n",
      "Epoch 48/50\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.4481\n",
      "Epoch 49/50\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.4442\n",
      "Epoch 50/50\n",
      "70/70 [==============================] - 1s 12ms/step - loss: 0.4532\n"
     ]
    }
   ],
   "source": [
    "x = np.reshape(x, (x.shape[0], 1, x.shape[1]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape = (x.shape[1], x.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mae', optimizer = 'adam')\n",
    "\n",
    "history = model.fit(x, np.array(y), epochs = 50, batch_size = 72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn into array\n",
    "array = np.array(lst)\n",
    "print(array.shape)\n",
    "\n",
    "# Apply PCA\n",
    "#\n",
    "# Documentation: \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "pca = PCA(n_components=3)\n",
    "pca_vectors_array = pca.fit_transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # JUST SOME FOURIER TRANSFORM PARAMETERS\n",
    "# BINS_OCTAVE = 12*2\n",
    "# N_OCTAVES = 7\n",
    "# NUM_BINS = BINS_OCTAVE * N_OCTAVES\n",
    "# SAMPLE_RATE = 22050\n",
    "\n",
    "# # Given a wav time series, makes a mel spectrogram\n",
    "# # which is a short-time fourier transform with\n",
    "# # frequencies on the mel (log) scale.\n",
    "# def mel_spec(y):\n",
    "#     y = np.array(y)\n",
    "#     Q = librosa.cqt(y=y, sr=SAMPLE_RATE, bins_per_octave=BINS_OCTAVE,n_bins=NUM_BINS)\n",
    "#     Q_db = librosa.amplitude_to_db(Q,ref=np.max)\n",
    "#     return Q_db\n",
    "\n",
    "# specshow(mel_spec(map(float, list(itertools.islice(reader, 0, 1))[0])), y_axis='hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Open file, save as reader object\n",
    "# f = open('train.csv', 'r')\n",
    "# reader = csv.reader(f)\n",
    "\n",
    "# # Get desired columns and rows from csv, \n",
    "# # Each row is a sublist inside of lst\n",
    "# # Right now it is taking rows 0 to 49\n",
    "# # and columns 0:4\n",
    "# # lst = []\n",
    "# n_mfcc = 20\n",
    "# x = np.zeros((1, n_mfcc))\n",
    "# y = []\n",
    "# for row in reader:\n",
    "#     y.append(int(float(row[-1])))\n",
    "#     array = np.append(\n",
    "#         array, \n",
    "#         np.mean(\n",
    "#             mfcc(np.array(map(float, row[:-1])), n_mfcc = n_mfcc), axis = 1\n",
    "#         ).reshape((1, n_mfcc)), \n",
    "#         axis = 0\n",
    "#     )\n",
    "#     x = np.append(x, np.array(map(float, row[:-1])).reshape((1, n_mfcc)), axis = 0)\n",
    "\n",
    "# y = to_categorical(y)\n",
    "# x = np.delete(x, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_dim = 88200\n",
    "# timesteps = 1\n",
    "# num_classes = 10\n",
    "\n",
    "# # Generate dummy training data\n",
    "# x_train = np.random.random((50, timesteps, data_dim))\n",
    "# y_train = [np.random.randint(num_classes) for _ in range(50)]\n",
    "# y_train = to_categorical(y_train)\n",
    "\n",
    "# assert(x_train.shape == (50, timesteps, data_dim))\n",
    "# assert(y_train.shape == (50, num_classes))\n",
    "\n",
    "# def f1():\n",
    "#     # expected input data shape: (batch_size, timesteps, data_dim)\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(32, return_sequences=True,\n",
    "#                    input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "#     model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "#     model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "#     model.add(Dense(10, activation='softmax'))\n",
    "#     model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer='rmsprop',\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "\n",
    "# estimator = KerasClassifier(build_fn = f1, epochs = 5, verbose = 1)\n",
    "# estimator.fit(x_train, y_train)\n",
    "# estimator.score(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
